#!/usr/bin/env ruby
require 'csv'
require 'sequel'
require 'fileutils'
require 'net/http'
require 'uri'
require 'yaml'

unless ENV['DATABASE_URL'] and ARGV.length <= 1
  abort "Usage: DATABASE_URL=postgres://localhost/mzalendo-zw #$0 [SITE-HOSTNAME]"
end

$hostname = (ARGV.length == 1) ? ARGV[0] : nil

DB = Sequel.connect(ENV['DATABASE_URL'])

LINK_REGEX = /\[(?<text>.+?)\]\((?<url>.+?)(?: (?<title>".*?"))?\)/

MEDIA_DIR = 'media'

$people_slugs_found = Set.new
$info_pages_found = Set.new
$other_path = Set.new

def fetch_file(path)
  request = Net::HTTP.new($hostname, '80')
  response = request.get(path)
  if response.code == "200"
    path.sub! /(\/)+$/, ''
    path.sub! /^\/media_root/, ''
    filename = File.join(MEDIA_DIR, path)
    directory_to_make = File.dirname(filename)
    FileUtils.mkdir_p directory_to_make
    open(filename, 'wb') { |f| f.write response.body }
    path
  elsif ["301", "302"].include? response.code
    location = response['location']
    location_uri_parsed = URI(location)
    if location_uri_parsed.host != $hostname
      raise "A Pombola path (#{path}) redirected off the site to #{location}"
    end
    fetch_file(location_uri_parsed.path)
  elsif response.code == "404"
    nil
  else
    raise "Unhandled status code #{response.code} for path #{path}"
  end
end

def is_pombola?(url)
  uri = URI(url)
  uri.host.nil? or uri.host == $hostname
end

def pombola_path(url)
  is_pombola?(url) ? URI(url).path : nil
end

def process_link(link_match)
  text, url, title = link_match.captures
  # Get rid of empty title
  title = nil if title == '""'
  # Fix relative links to be absolute
  unless url.lstrip.start_with?('/') or url.lstrip.start_with?('http')
    url = "/info/#{url.strip}"
  end
  # Rewrite a known bad URL:
  url.gsub!(/jibrin-b rau/, 'jibrin-barau')
  url.gsub!(%r'^/info/revoda.org.ng', 'http://www.revoda.org.ng/')
  if $hostname
    path = pombola_path(url)
    if path
      if path =~ %r'^/(file_archive|media_root)/'
        url = fetch_file(path)
      elsif path =~ %r'^/person/(?<person_slug>[-a-zA-Z0-9]+)(?:/(?<person_subpage>.*?)/?)$'
        person_slug, subpage = Regexp.last_match.captures
        $people_slugs_found.add person_slug
      elsif path =~ %r'^/info/(.*)'
        info_page_slug = Regexp.last_match(1)
        $info_pages_found.add info_page_slug
      else
        $other_path.add path
      end
    end
  end
  "[#{text}](#{url}#{title ? ' ' + title : ''})"
end

def tidy_markdown(markdown)
  markdown.tr!("\r\n", "\n")
  markdown.gsub!(/\n+$/, "\n")
  markdown.gsub!("\n\n**\n", "**\n")
  markdown.strip!
  markdown.gsub!(LINK_REGEX) { |m| process_link Regexp.last_match }
  markdown
end

def content_for(item, front_matter = {})
  <<CONTENT
#{YAML.dump(front_matter)}---

#{tidy_markdown(item[:markdown_content])}
CONTENT
end

infopages_path = 'info'
FileUtils.mkdir_p(infopages_path)

DB[:info_infopage].where(kind: 'page').each do |page|
  front_matter = {
    'title' => page[:title].strip,
    'slug' => page[:slug],
    'permalink' => "/info/#{page[:slug]}/",
    'layout' => 'page'
  }
  File.write(File.join(infopages_path, "#{page[:slug]}.md"), content_for(page, front_matter))
end

posts_path = 'posts'
FileUtils.mkdir_p(posts_path)

DB[:info_infopage].exclude(kind: 'page').each do |post|
  front_matter = {
    'title' => post[:title].strip,
    'slug' => post[:slug],
    'layout' => 'post'
  }
  File.write(File.join(posts_path, "#{post[:publication_date].to_date.to_s}-#{post[:slug]}.md"), content_for(post, front_matter))
end

[
  ['people_linked_to.csv', $people_slugs_found],
  ['info_pages_linked_to.csv', $info_pages_found],
  ['other_linked_to.csv', $other_path]
].each do |output_filename, value_set|
  CSV.open(output_filename, 'wb') do |csv|
    value_set.to_a.sort.each { |v| csv << [v] }
  end
end
